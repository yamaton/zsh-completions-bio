#compdef vg

# Auto-generated with h2o


function _vg {
    local line state

    function _commands {
        local -a commands
        commands=(
            'autoindex:mapping tool-oriented index construction from interchange formats'
            'construct:graph construction'
            'rna:construct splicing graphs and pantranscriptomes'
            'index:index graphs or alignments for random access or mapping'
            'giraffe:fast haplotype-aware short read alignment'
            'mpmap:splice-aware multipath alignment of short reads'
            'augment:augment a graph from an alignment'
            'pack:convert alignments to a compact coverage index'
            'call:call or genotype VCF variants'
            'help:show all subcommands'
            'deconstruct:create a VCF from variation in the graph'
            'gbwt:build and manipulate GBWTs'
            'ids:manipulate node ids'
            'minimizer:build a minimizer index or a syncmer index'
            'mod:filter, transform, and edit the graph'
            'prune:prune the graph for GCSA2 indexing'
            'sim:simulate reads from a graph'
            'snarls:compute snarls and their traversals'
            'stats:metrics describing graph and alignment properties'
            'view:format conversions for graphs and alignments'
            'align:local alignment'
            'annotate:annotate alignments with graphs and graphs with alignments'
            'chunk:split graph or alignment into chunks'
            'circularize:circularize a path within a graph'
            'clip:remove BED regions (other other nodes from their snarls) from a graph'
            'combine:merge multiple graph files together'
            'convert:convert graphs between handle-graph compliant formats as well as GFA'
            'depth:estimate sequencing depth'
            'dotplot:generate the dotplot matrix from the embedded paths in an xg index'
            'gamcompare:compare alignment positions'
            'gampcompare:compare multipath alignment positions'
            'gamsort:Sort a GAM file or index a sorted GAM file.'
            'genotype:Genotype (or type) graphs, GAMS, and VCFs.'
            'inject:lift over alignments for the graph'
            'paths:traverse paths in the graph'
            'simplify:graph simplification'
            'surject:map alignments onto specific paths'
            'trace:trace haplotypes'
            'vectorize:transform alignments to simple ML-compatible vectors'
            'viz:render visualizations of indexed graphs and read sets'
            'benchmark:run and report on performance benchmarks'
            'chain:run a serialized chaining problem'
            'cluster:find and cluster mapping seeds'
            'find:use an index to find nodes, edges, kmers, paths, or positions'
            'mcmc:Finds haplotypes based on reads using MCMC methods'
            'test:run unit tests'
            'validate:validate the semantics of a graph or gam'
            'version:version information'
        )
        _describe 'command' commands
    }
 

    _arguments -C \
        ': :->cmd' \
        '*:: :->subcmd'

    case $state in
    (cmd)
        _commands
        ;;
    (subcmd)
        case $line[1] in
        (autoindex)
            _vg_autoindex
            ;;

        (construct)
            _vg_construct
            ;;

        (rna)
            _vg_rna
            ;;

        (index)
            _vg_index
            ;;

        (giraffe)
            _vg_giraffe
            ;;

        (mpmap)
            _vg_mpmap
            ;;

        (augment)
            _vg_augment
            ;;

        (pack)
            _vg_pack
            ;;

        (call)
            _vg_call
            ;;

        (help)
            _vg_help
            ;;

        (deconstruct)
            _vg_deconstruct
            ;;

        (gbwt)
            _vg_gbwt
            ;;

        (ids)
            _vg_ids
            ;;

        (minimizer)
            _vg_minimizer
            ;;

        (mod)
            _vg_mod
            ;;

        (prune)
            _vg_prune
            ;;

        (sim)
            _vg_sim
            ;;

        (snarls)
            _vg_snarls
            ;;

        (stats)
            _vg_stats
            ;;

        (view)
            _vg_view
            ;;

        (align)
            _vg_align
            ;;

        (annotate)
            _vg_annotate
            ;;

        (chunk)
            _vg_chunk
            ;;

        (circularize)
            _vg_circularize
            ;;

        (clip)
            _vg_clip
            ;;

        (combine)
            _vg_combine
            ;;

        (convert)
            _vg_convert
            ;;

        (depth)
            _vg_depth
            ;;

        (dotplot)
            _vg_dotplot
            ;;

        (gamcompare)
            _vg_gamcompare
            ;;

        (gampcompare)
            _vg_gampcompare
            ;;

        (gamsort)
            _vg_gamsort
            ;;

        (genotype)
            _vg_genotype
            ;;

        (inject)
            _vg_inject
            ;;

        (paths)
            _vg_paths
            ;;

        (simplify)
            _vg_simplify
            ;;

        (surject)
            _vg_surject
            ;;

        (trace)
            _vg_trace
            ;;

        (vectorize)
            _vg_vectorize
            ;;

        (viz)
            _vg_viz
            ;;

        (benchmark)
            _vg_benchmark
            ;;

        (chain)
            _vg_chain
            ;;

        (cluster)
            _vg_cluster
            ;;

        (find)
            _vg_find
            ;;

        (mcmc)
            _vg_mcmc
            ;;

        (test)
            _vg_test
            ;;

        (validate)
            _vg_validate
            ;;

        (version)
            _vg_version
            ;;

        esac
        ;;
     esac

}

function _vg_autoindex {
    _arguments \
        {-p,--prefix}'[prefix to use for all output (default: index)]' \
        {-w,--workflow}'[workflow to produce indexes for, can be provided multiple times. options: map, mpmap, rpvg, giraffe (default: map)]' \
        {-r,--ref-fasta}'[FASTA file containing the reference sequence (may repeat)]':file:_files \
        {-v,--vcf}'[VCF file with sequence names matching -r (may repeat)]':file:_files \
        {-i,--ins-fasta}'[FASTA file with sequences of INS variants from -v]':file:_files \
        {-g,--gfa}'[GFA file to make a graph from]':file:_files \
        {-x,--tx-gff}'[GTF/GFF file with transcript annotations (may repeat)]':file:_files \
        {-f,--gff-feature}'[GTF/GFF feature type (col. 3) to add to graph (default: exon)]' \
        {-a,--gff-tx-tag}'[GTF/GFF tag (in col. 9) for transcript ID (default: transcript_id)]' \
        {-T,--tmp-dir}'[temporary directory to use for intermediate files]':file:_files \
        {-M,--target-mem}'[target max memory usage (not exact, formatted INT\[kMG\]) (default: 1/2 of available)]' \
        {-t,--threads}'[number of threads (default: all available)]' \
        {-V,--verbosity}'[log to stderr (0 = none, 1 = basic, 2 = debug; default 1)]' \
        {-h,--help}'[print this help message to stderr and exit]' \
        "*: :_files"

}

function _vg_construct {
    _arguments \
        {-r,--reference}'[input FASTA reference (may repeat)]':file:_files \
        {-v,--vcf}'[input VCF (may repeat)]':file:_files \
        {-n,--rename}'[match contig V in the VCFs to contig F in the FASTAs (may repeat)]' \
        {-a,--alt-paths}'[save paths for alts of variants by variant ID]' \
        {-R,--region}'[specify a VCF contig name or 1-based inclusive region (may repeat, if on different contigs)]' \
        {-C,--region-is-chrom}'[don'\''t attempt to parse the regions (use when the reference sequence name could be inadvertently parsed as a region)]' \
        {-z,--region-size}'[variants per region to parallelize (default: 1024)]' \
        {-t,--threads}'[use N threads to construct graph (defaults to numCPUs)]' \
        {-S,--handle-sv}'[include structural variants in construction of graph.]' \
        {-I,--insertions}'[a FASTA file containing insertion sequences (referred to in VCF) to add to graph.]':file:_files \
        {-f,--flat-alts}'[don'\''t chop up alternate alleles from input VCF]' \
        {-l,--parse-max}'[don'\''t chop up alternate alleles from input VCF longer than N (default: 100)]' \
        {-i,--no-trim-indels}'[don'\''t remove the 1bp reference base from alt alleles of indels.]' \
        {-M,--msa}'[input multiple sequence alignment]':file:_files \
        {-F,--msa-format}'[format of the MSA file (options: fasta, clustal; default fasta)]' \
        {-d,--drop-msa-paths}'[don'\''t add paths for the MSA sequences into the graph]' \
        {-m,--node-max}'[limit the maximum allowable node sequence size (default: 32) nodes greater than this threshold will be divided Note: nodes larger than ~1024 bp can'\''t be GCSA2-indexed]' \
        {-p,--progress}'[show progress]' \
        "*: :_files"

}

function _vg_rna {
    _arguments \
        {-t,--threads}'[number of compute threads to use \[1\]]' \
        {-p,--progress}'[show progress]' \
        {-h,--help}'[print help message]' \
        {-n,--transcripts}'[transcript file(s) in gtf/gff format; may repeat]':file:_files \
        {-m,--introns}'[intron file(s) in bed format; may repeat]':file:_files \
        {-y,--feature-type}'[parse only this feature type in the gtf/gff (parses all if empty) \[exon\]]' \
        {-s,--transcript-tag}'[use this attribute tag in the gtf/gff file(s) as id \[transcript_id\]]' \
        {-l,--haplotypes}'[project transcripts onto haplotypes in GBWT index file]':file:_files \
        {-j,--use-hap-ref}'[use haplotype paths in GBWT index as reference sequences (disables projection)]' \
        {-e,--proj-embed-paths}'[project transcripts onto embedded haplotype paths]' \
        {-c,--path-collapse}'[collapse identical transcript paths across no|haplotype|all paths \[haplotype\]]' \
        {-k,--max-node-length}'[chop nodes longer than maximum node length (0 disables chopping) \[0\]]' \
        {-d,--remove-non-gene}'[remove intergenic and intronic regions (deletes all paths in the graph)]' \
        {-o,--do-not-sort}'[do not topological sort and compact the graph]' \
        {-r,--add-ref-paths}'[add reference transcripts as embedded paths in the graph]' \
        {-a,--add-hap-paths}'[add projected transcripts as embedded paths in the graph]' \
        {-b,--write-gbwt}'[write pantranscriptome transcript paths as GBWT index file]':file:_files \
        {-f,--write-fasta}'[write pantranscriptome transcript sequences as fasta file]':file:_files \
        {-i,--write-info}'[write pantranscriptome transcript info table as tsv file]':file:_files \
        {-q,--out-exclude-ref}'[exclude reference transcripts from pantranscriptome output]' \
        {-g,--gbwt-bidirectional}'[use bidirectional paths in GBWT index construction]' \
        "*: :_files"

}

function _vg_index {
    _arguments \
        {-b,--temp-dir}'[use DIR for temporary files]':file:_files \
        {-t,--threads}'[number of threads to use]' \
        {-p,--progress}'[show progress]' \
        {-x,--xg-name}'[use this file to store a succinct, queryable version of the graph(s), or read for GCSA or distance indexing]':file:_files \
        {-L,--xg-alts}'[include alt paths in xg]' \
        {-v,--vcf-phasing}'[generate threads from the haplotypes in the VCF file FILE]':file:_files \
        {-W,--ignore-missing}'[don'\''t warn when variants in the VCF are missing from the graph; silently skip them]' \
        {-T,--store-threads}'[generate threads from the embedded paths]' \
        {-M,--store-gam}'[generate threads from the alignments in gam FILE (many allowed)]':file:_files \
        {-F,--store-gaf}'[generate threads from the alignments in gaf FILE (many allowed)]':file:_files \
        {-G,--gbwt-name}'[store the threads as GBWT in FILE]':file:_files \
        {-z,--actual-phasing}'[do not make unphased homozygous genotypes phased]' \
        {-P,--force-phasing}'[replace unphased genotypes with randomly phased ones]' \
        {-o,--discard-overlaps}'[skip overlapping alternate alleles if the overlap cannot be resolved]' \
        {-B,--batch-size}'[number of samples per batch (default 200)]' \
        {-u,--buffer-size}'[GBWT construction buffer size in millions of nodes (default 100)]' \
        {-n,--id-interval}'[store haplotype ids at one out of N positions (default 1024)]' \
        {-R,--range}'[process samples X to Y (inclusive)]' \
        {-r,--rename}'[rename contig V in the VCFs to path P in the graph (may repeat)]' \
        '--rename-variants[when renaming contigs, find variants in the graph based on the new name]' \
        {-I,--region}'[operate on only the given 1-based region of the given VCF contig (may repeat)]' \
        {-E,--exclude}'[exclude any samples with the given name from haplotype indexing]' \
        {-g,--gcsa-out}'[output a GCSA2 index to the given file]':file:_files \
        {-f,--mapping}'[use this node mapping in GCSA2 construction]':file:_files \
        {-k,--kmer-size}'[index kmers of size N in the graph (default 16)]' \
        {-X,--doubling-steps}'[use this number of doubling steps for GCSA2 construction (default 4)]' \
        {-Z,--size-limit}'[limit temporary disk space usage to N gigabytes (default 2048)]' \
        {-V,--verify-index}'[validate the GCSA2 index using the input kmers (important for testing)]' \
        '--index-sorted-vg[input is ID-sorted .vg format graph chunks, store a VGI index of the sorted vg in INPUT.vg.vgi]' \
        '-j[--dist-name FILE use this file to store a snarl-based distance index]' \
        '--snarl-limit[don'\''t store snarl distances for snarls with more than N nodes (default 3000)]' \
        '-w[--distance-limit N cap beyond which the minimum distance is no longer accurate (default inf)]' \
        "*: :_files"

}

function _vg_giraffe {
    _arguments \
        {-Z,--gbz-name}'[use this GBZ file (GBWT index + GBWTGraph)]':file:_files \
        {-m,--minimizer-name}'[use this minimizer index]':file:_files \
        {-d,--dist-name}'[cluster using this distance index]':file:_files \
        {-p,--progress}'[show progress]' \
        {-G,--gam-in}'[read and realign GAM-format reads from FILE]':file:_files \
        {-f,--fastq-in}'[read and align FASTQ-format reads from FILE (two are allowed, one for each mate)]':file:_files \
        {-i,--interleaved}'[GAM/FASTQ input is interleaved pairs, for paired-end alignment]' \
        {-x,--xg-name}'[use this xg index or graph]':file:_files \
        {-g,--graph-name}'[use this GBWTGraph]':file:_files \
        {-H,--gbwt-name}'[use this GBWT index]':file:_files \
        {-N,--sample}'[add this sample name]' \
        {-R,--read-group}'[add this read group]' \
        {-o,--output-format}'[output the alignments in NAME format (gam / gaf / json / tsv / SAM / BAM / CRAM) \[gam\]]' \
        '--ref-paths[ordered list of paths in the graph, one per line or HTSlib .dict, for HTSLib @SQ headers]':file:_files \
        '--named-coordinates[produce GAM outputs in named-segment (GFA) space]' \
        {-P,--prune-low-cplx}'[prune short and low complexity anchors during linear format realignment]' \
        {-n,--discard}'[discard all output alignments (for profiling)]' \
        '--output-basename[write output to a GAM file beginning with the given prefix for each setting combination]' \
        '--report-name[write a TSV of output file and mapping speed to the given file]' \
        '--show-work[log how the mapper comes to its conclusions about mapping locations]' \
        {-b,--parameter-preset}'[set computational parameters (fast / default) \[default\]]' \
        {-M,--max-multimaps}'[produce up to INT alignments for each read \[1\]]' \
        {-c,--hit-cap}'[use all minimizers with at most INT hits \[10\]]' \
        {-C,--hard-hit-cap}'[ignore all minimizers with more than INT hits \[500\]]' \
        {-F,--score-fraction}'[select minimizers between hit caps until score is FLOAT of total \[0.9\]]' \
        {-U,--max-min}'[use at most INT minimizers \[500\]]' \
        '--num-bp-per-min[use maximum of number minimizers calculated by READ_LENGTH / INT and --max-min \[1000\]]' \
        {-D,--distance-limit}'[cluster using this distance limit \[200\]]' \
        {-e,--max-extensions}'[extend up to INT clusters \[800\]]' \
        {-a,--max-alignments}'[align up to INT extensions \[8\]]' \
        {-s,--cluster-score}'[only extend clusters if they are within INT of the best score \[50\]]' \
        {-S,--pad-cluster-score}'[also extend clusters within INT of above threshold to get a second-best cluster \[20\]]' \
        {-u,--cluster-coverage}'[only extend clusters if they are within FLOAT of the best read coverage \[0.3\]]' \
        {-v,--extension-score}'[only align extensions if their score is within INT of the best score \[1\]]' \
        {-w,--extension-set}'[only align extension sets if their score is within INT of the best score \[20\]]' \
        {-O,--no-dp}'[disable all gapped alignment]' \
        {-r,--rescue-attempts}'[attempt up to INT rescues per read in a pair \[15\]]' \
        {-L,--max-fragment-length}'[assume that fragment lengths should be smaller than INT when estimating the fragment length distribution \[2000\]]' \
        '--exclude-overlapping-min[exclude overlapping minimizers]' \
        '--paired-distance-limit[cluster pairs of read using a distance limit FLOAT standard deviations greater than the mean \[2\]]' \
        '--rescue-subgraph-size[search for rescued alignments FLOAT standard deviations greater than the mean \[4\]]' \
        '--rescue-seed-limit[attempt rescue with at most INT seeds \[100\]]' \
        '--align-from-chains[chain up extensions to create alignments, instead of doing each separately]' \
        '--chaining-cluster-distance[maximum distance to cluster over before chaining \[80\]]' \
        '--max-lookback-bases[maximum distance to look back when chaining \[80\]]' \
        '--min-lookback-items[minimum items to look back when chaining \[1\]]' \
        '--max-chain-connection[maximum distance across which to connect seeds when aligning a chain \[80\]]' \
        '--max-tail-length[maximum length of a tail to align before forcing softclipping when aligning a chain \[100\]]' \
        {-A,--rescue-algorithm}'[use algorithm NAME for rescue (none / dozeu / gssw) \[dozeu\]]' \
        '--fragment-mean[force the fragment length distribution to have this mean (requires --fragment-stdev)]' \
        '--fragment-stdev[force the fragment length distribution to have this standard deviation (requires --fragment-mean)]' \
        '--track-provenance[track how internal intermediate alignment candidates were arrived at]' \
        '--track-correctness[track if internal intermediate alignment candidates are correct (implies --track-provenance)]' \
        {-B,--batch-size}'[number of reads or pairs per batch to distribute to threads \[512\]]' \
        {-t,--threads}'[number of mapping threads to use]' \
        "*: :_files"

}

function _vg_mpmap {
    _arguments \
        {-x,--graph-name}'[graph (required; XG format recommended but other formats are valid, see `vg convert`)]':file:_files \
        {-g,--gcsa-name}'[use this GCSA2/LCP index pair for MEMs (required; both FILE and FILE.lcp, see `vg index`)]':file:_files \
        {-d,--dist-name}'[use this snarl distance index for clustering (recommended, see `vg index`)]':file:_files \
        {-s,--snarls}'[align to alternate paths in these snarls (unnecessary if providing -d, see `vg snarls`)]':file:_files \
        {-f,--fastq}'[input FASTQ (possibly gzipped), can be given twice for paired ends (for stdin use -)]':file:_files \
        {-i,--interleaved}'[input contains interleaved paired ends]' \
        {-n,--nt-type}'[sequence type preset: '\''DNA'\'' for genomic data, '\''RNA'\'' for transcriptomic data \[RNA\]]' \
        {-l,--read-length}'[read length preset: '\''very-short'\'', '\''short'\'', or '\''long'\'' (approx. <50bp, 50-500bp, and >500bp) \[short\]]' \
        {-e,--error-rate}'[error rate preset: '\''low'\'' or '\''high'\'' (approx. PHRED >20 and <20) \[low\]]' \
        {-F,--output-fmt}'[format to output alignments in: '\''GAMP for'\'' multipath alignments, '\''GAM'\'' or '\''GAF'\'' for single-path alignments, '\''SAM'\'', '\''BAM'\'', or '\''CRAM'\'' for linear reference alignments (may also require -S) \[GAMP\]]' \
        {-S,--ref-paths}'[paths in the graph either 1) one per line in a text file, or 2) in an HTSlib .dict, to treat as reference sequences for HTSlib formats (see -F) \[all paths\]]':file:_files \
        {-N,--sample}'[add this sample name to output]' \
        {-R,--read-group}'[add this read group to output]' \
        {-p,--suppress-progress}'[do not report progress to stderr]' \
        {-t,--threads}'[number of compute threads to use \[all available\]]' \
        {-X,--not-spliced}'[do not form spliced alignments, even if aligning with --nt-type '\''rna'\'']' \
        {-M,--max-multimaps}'[report (up to) this many mappings per read \[10 rna / 1 dna\]]' \
        {-a,--agglomerate-alns}'[combine separate multipath alignments into one (possibly disconnected) alignment]' \
        {-r,--intron-distr}'[intron length distribution (from scripts/intron_length_distribution.py)]':file:_files \
        {-Q,--mq-max}'[cap mapping quality estimates at this much \[60\]]' \
        {-b,--frag-sample}'[look for this many unambiguous mappings to estimate the fragment length distribution \[1000\]]' \
        {-I,--frag-mean}'[mean for a pre-determined fragment length distribution (also requires -D)]' \
        {-D,--frag-stddev}'[standard deviation for a pre-determined fragment length distribution (also requires -I)]' \
        {-G,--gam-input}'[input GAM (for stdin, use -)]':file:_files \
        {-u,--map-attempts}'[perform (up to) this many mappings per read (0 for no limit) \[24 paired / 64 unpaired\]]' \
        {-c,--hit-max}'[use at most this many hits for any match seeds (0 for no limit) \[1024 DNA / 100 RNA\]]' \
        {-A,--no-qual-adjust}'[do not perform base quality adjusted alignments even when base qualities are available]' \
        {-q,--match}'[use this match score \[1\]]' \
        {-z,--mismatch}'[use this mismatch penalty \[4 low error, 1 high error\]]' \
        {-o,--gap-open}'[use this gap open penalty \[6 low error, 1 high error\]]' \
        {-y,--gap-extend}'[use this gap extension penalty \[1\]]' \
        {-L,--full-l-bonus}'[add this score to alignments that align each end of the read \[mismatch+1 short, 0 long\]]' \
        {-w,--score-matrix}'[read a 4x4 integer substitution scoring matrix from a file (in the order ACGT)]':file:_files \
        {-m,--remove-bonuses}'[remove full length alignment bonuses in reported scores]' \
        "*: :_files"

}

function _vg_augment {
    _arguments \
        {-i,--include-paths}'[merge the paths implied by alignments into the graph]' \
        {-S,--keep-softclips}'[include softclips from input alignments (they are cut by default)]' \
        {-B,--label-paths}'[don'\''t augment with alignments, just use them for labeling the graph]' \
        {-Z,--translation}'[save translations from augmented back to base graph to FILE]':file:_files \
        {-A,--alignment-out}'[save augmented GAM reads to FILE]':file:_files \
        {-F,--gaf}'[expect (and write) GAF instead of GAM]' \
        {-s,--subgraph}'[graph is a subgraph of the one used to create GAM. ignore alignments with missing nodes]' \
        {-m,--min-coverage}'[minimum coverage of a breakpoint required for it to be added to the graph]' \
        {-c,--expected-cov}'[expected coverage. used only for memory tuning \[default : 128\]]' \
        {-q,--min-baseq}'[ignore edits whose sequence have average base quality < N]' \
        {-Q,--min-mapq}'[ignore alignments with mapping quality < N]' \
        {-N,--max-n}'[maximum fraction of N bases in an edit for it to be included \[default : 0.25\]]' \
        {-E,--edges-only}'[only edges implied by reads, ignoring edits]' \
        {-h,--help}'[print this help message]' \
        {-p,--progress}'[show progress]' \
        {-v,--verbose}'[print information and warnings about vcf generation]' \
        {-t,--threads}'[number of threads (only 1st pass with -m or -q option is multithreaded)]' \
        {-l,--include-loci}'[merge all alleles in loci into the graph]':file:_files \
        {-L,--include-gt}'[merge only the alleles in called genotypes into the graph]':file:_files \
        "*: :_files"

}

function _vg_pack {
    _arguments \
        {-x,--xg}'[use this basis graph (any format accepted, does not have to be xg)]':file:_files \
        {-o,--packs-out}'[write compressed coverage packs to this output file]':file:_files \
        {-i,--packs-in}'[begin by summing coverage packs from each provided FILE]':file:_files \
        {-g,--gam}'[read alignments from this GAM file (could be '\''-'\'' for stdin)]':file:_files \
        {-a,--gaf}'[read alignments from this GAF file (could be '\''-'\'' for stdin)]':file:_files \
        {-d,--as-table}'[write table on stdout representing packs]' \
        {-D,--as-edge-table}'[write table on stdout representing edge coverage]' \
        {-u,--as-qual-table}'[write table on stdout representing average node mapqs]' \
        {-e,--with-edits}'[record and write edits rather than only recording graph-matching coverage]' \
        {-b,--bin-size}'[number of sequence bases per CSA bin \[default: inf\]]' \
        {-n,--node}'[write table for only specified node(s)]' \
        {-N,--node-list}'[a white space or line delimited list of nodes to collect]':file:_files \
        {-Q,--min-mapq}'[ignore reads with MAPQ < N and positions with base quality < N \[default: 0\]]' \
        {-c,--expected-cov}'[expected coverage. used only for memory tuning \[default : 128\]]' \
        {-s,--trim-ends}'[ignore the first and last N bases of each read]' \
        {-t,--threads}'[use N threads (defaults to numCPUs)]' \
        "*: :_files"

}

function _vg_call {
    _arguments \
        {-k,--pack}'[Supports created from vg pack for given input graph]':file:_files \
        {-m,--min-support}'[Minimum allele support (M) and minimum site support (N) for call \[default = 2,4\]]' \
        {-e,--baseline-error}'[Baseline error rates for Poisson model for small (X) and large (Y) variants \[default= 0.005,0.01\]]' \
        {-B,--bias-mode}'[Use old ratio-based genotyping algorithm as opposed to porbablistic model]' \
        {-b,--het-bias}'[Homozygous alt/ref allele must have >= M/N times more support than the next best allele \[default = 6,6\]]' \
        {-G,--gaf}'[Output GAF genotypes instead of VCF]' \
        {-T,--traversals}'[Output all candidate traversals in GAF without doing any genotyping]' \
        {-M,--trav-padding}'[Extend each flank of traversals (from -T) with reference path by N bases if possible]' \
        {-v,--vcf}'[VCF file to genotype (must have been used to construct input graph with -a)]':file:_files \
        {-a,--genotype-snarls}'[Genotype every snarl, including reference calls (use to compare multiple samples)]' \
        {-A,--all-snarls}'[Genotype all snarls, including nested child snarls (like deconstruct -a)]' \
        {-c,--min-length}'[Genotype only snarls with reference traversal length >= N]' \
        {-C,--max-length}'[Genotype only snarls with reference traversal length <= N]' \
        {-f,--ref-fasta}'[Reference fasta (required if VCF contains symbolic deletions or inversions)]':file:_files \
        {-i,--ins-fasta}'[Insertions fasta (required if VCF contains symbolic insertions)]':file:_files \
        {-s,--sample}'[Sample name \[default=SAMPLE\]]' \
        {-r,--snarls}'[Snarls (from vg snarls) to avoid recomputing.]':file:_files \
        {-g,--gbwt}'[Only call genotypes that are present in given GBWT index.]':file:_files \
        {-z,--gbz}'[Only call genotypes that are present in GBZ index (applies only if input graph is GBZ).]' \
        {-N,--translation}'[Node ID translation (as created by vg gbwt --translation) to apply to snarl names in output]':file:_files \
        {-p,--ref-path}'[Reference path to call on (multipile allowed. defaults to all paths)]' \
        {-o,--ref-offset}'[Offset in reference path (multiple allowed, 1 per path)]' \
        {-l,--ref-length}'[Override length of reference in the contig field of output VCF]' \
        {-d,--ploidy}'[Ploidy of sample. Only 1 and 2 supported. (default: 2)]' \
        {-n,--nested}'[Activate nested calling mode (experimental)]' \
        {-I,--chains}'[Call chains instead of snarls (experimental)]' \
        {-t,--threads}'[number of threads to use]' \
        {-R,--ploidy-regex}'[use the given comma-separated list of colon-delimited REGEX:PLOIDY rules to assign ploidies to contigs not visited by the selected samples, or to all contigs simulated from if no samples are used. Unmatched contigs get ploidy 2 (or that from -d).]' \
        "*: :_files"

}

function _vg_help {
    _arguments \
        "*: :_files"

}

function _vg_deconstruct {
    _arguments \
        {-p,--path}'[A reference path to deconstruct against (multiple allowed).]' \
        {-P,--path-prefix}'[All paths (and/or GBWT threads) beginning with NAME used as reference (multiple allowed). Other non-ref paths not considered as samples. When using a GBWT, select only samples with given prefix.]' \
        {-H,--path-sep}'[Obtain alt paths from the set of paths, assuming a path name hierarchy (e.g. SEP='\''#'\'' and sample#phase#contig)]' \
        {-r,--snarls}'[Snarls file (from vg snarls) to avoid recomputing.]':file:_files \
        {-g,--gbwt}'[only consider alt traversals that correspond to GBWT threads FILE (not needed for GBZ graph input).]':file:_files \
        {-T,--translation}'[Node ID translation (as created by vg gbwt --translation) to apply to snarl names in output]':file:_files \
        {-e,--path-traversals}'[Only consider traversals that correspond to paths in the graph.]' \
        {-a,--all-snarls}'[Process all snarls, including nested snarls (by default only top-level snarls reported).]' \
        {-d,--ploidy}'[Expected ploidy. If more traversals found, they will be flagged as conflicts (default: 2)]' \
        {-c,--context-jaccard}'[Set context mapping size used to disambiguate alleles at sites with multiple reference traversals (default: 10000).]' \
        {-u,--untangle-travs}'[Use context mapping to determine the reference-relative positions of each step in allele traversals (AP INFO field).]' \
        {-K,--keep-conflicted}'[Retain conflicted genotypes in output.]' \
        {-S,--strict-conflicts}'[Drop genotypes when we have more than one haplotype for any given phase (set by default when using GBWT input).]' \
        {-t,--threads}'[Use N threads]' \
        {-v,--verbose}'[Print some status messages]' \
        "*: :_files"

}

function _vg_gbwt {
    _arguments \
        {-x,--xg-name}'[read the graph from FILE]':file:_files \
        {-o,--output}'[write output GBWT to FILE]':file:_files \
        {-d,--temp-dir}'[use directory DIR for temporary files]':file:_files \
        {-p,--progress}'[show progress and statistics]' \
        '--buffer-size[GBWT construction buffer size in millions of nodes (default 100)]' \
        '--id-interval[store path ids at one out of N positions (default 1024)]' \
        '--num-jobs[use at most N parallel build jobs (for -v and -G; default 6)]' \
        '--num-threads[use N parallel search threads (for -b and -r; default 12)]' \
        {-v,--vcf-input}'[index the haplotypes in the VCF files specified in input args in parallel (inputs must be over different contigs; requires -x, implies -f) (does not store graph contigs in the GBWT)]' \
        '--preset[use preset X (available: 1000gp)]' \
        '--inputs-as-jobs[create one build job for each input instead of using first-fit heuristic]' \
        '--parse-only[store the VCF parses without building GBWTs (use -o for the file name prefix; skips subsequent steps)]' \
        '--ignore-missing[do not warn when variants are missing from the graph]' \
        '--actual-phasing[do not interpret unphased homozygous genotypes as phased]' \
        '--force-phasing[replace unphased genotypes with randomly phased ones]' \
        '--discard-overlaps[skip overlapping alternate alleles if the overlap cannot be resolved instead of creating a phase break]' \
        '--batch-size[index the haplotypes in batches of N samples (default 200)]' \
        '--sample-range[index samples X to Y (inclusive, 0-based)]' \
        '--rename[VCF contig V matches path P in the graph (may repeat)]' \
        '--vcf-variants[variants in the graph use VCF contig names instead of path names]' \
        '--vcf-region[restrict VCF contig C to coordinates X to Y (inclusive, 1-based; may repeat)]' \
        '--exclude-sample[do not index the sample with name X (faster than -R; may repeat)]' \
        {-G,--gfa-input}'[index the walks or paths in the GFA file (one input arg)]' \
        '--max-node[chop long segments into nodes of at most N bp (default 1024, use 0 to disable)]' \
        '--path-regex[parse metadata as haplotypes from path names using regex X instead of vg-parser-compatible rules]' \
        '--path-fields[parse metadata as haplotypes, mapping regex submatches to these fields instead of using vg-parser-compatible rules]' \
        '--translation[write the segment to node translation table to FILE]':file:_files \
        {-Z,--gbz-input}'[extract GBWT and GBWTGraph from GBZ input (one input arg)]' \
        {-E,--index-paths}'[index the embedded non-alt paths in the graph (requires -x, no input args)]' \
        {-A,--alignment-input}'[index the alignments in the GAF files specified in input args (requires -x)]' \
        '--gam-format[the input files are in GAM format instead of GAF format]' \
        {-m,--merge}'[use the insertion algorithm]' \
        {-f,--fast}'[fast merging algorithm (node ids must not overlap)]' \
        {-b,--parallel}'[use the parallel algorithm]' \
        '--chunk-size[search in chunks of N sequences (default 1)]' \
        '--pos-buffer[use N MiB position buffers for each search thread (default 64)]' \
        '--thread-buffer[use N MiB thread buffers for each search thread (default 256)]' \
        '--merge-buffers[merge 2^N thread buffers into one file per merge job (default 6)]' \
        '--merge-jobs[run N parallel merge jobs (default 4)]' \
        {-R,--remove-sample}'[remove the sample with name X from the index (may repeat)]' \
        '--set-tag[set a GBWT tag (may repeat)]' \
        {-a,--augment-gbwt}'[add a path cover of missing components (one input GBWT)]' \
        {-l,--local-haplotypes}'[sample local haplotypes (one input GBWT)]' \
        {-P,--path-cover}'[build a greedy path cover (no input GBWTs)]' \
        {-n,--num-paths}'[find N paths per component (default 64 for -l, 16 otherwise)]' \
        {-k,--context-length}'[use N-node contexts (default 4)]' \
        '--pass-paths[include named graph paths in local haplotype or greedy path cover GBWT]' \
        {-g,--graph-name}'[build GBWTGraph and store it in FILE]':file:_files \
        '--gbz-format[serialize both GBWT and GBWTGraph in GBZ format (makes -o unnecessary)]' \
        {-r,--r-index}'[build an r-index and store it in FILE]':file:_files \
        {-M,--metadata}'[print basic metadata]' \
        {-C,--contigs}'[print the number of contigs]' \
        {-H,--haplotypes}'[print the number of haplotypes]' \
        {-S,--samples}'[print the number of samples]' \
        {-L,--list-names}'[list contig/sample names (use with -C or -S)]' \
        {-T,--thread-names}'[list thread names]' \
        '--tags[list GBWT tags]' \
        {-c,--count-threads}'[print the number of threads]' \
        {-e,--extract}'[extract threads in SDSL format to FILE]':file:_files \
        "*: :_files"

}

function _vg_ids {
    _arguments \
        {-c,--compact}'[minimize the space of integers used by the ids]' \
        {-i,--increment}'[increase ids by N]' \
        {-d,--decrement}'[decrease ids by N]' \
        {-j,--join}'[make a joint id space for all the graphs that are supplied by iterating through the supplied graphs and incrementing their ids to be non-conflicting (modifies original files)]' \
        {-m,--mapping}'[create an empty node mapping for vg prune]':file:_files \
        {-s,--sort}'[assign new node IDs in (generalized) topological sort order]' \
        "*: :_files"

}

function _vg_minimizer {
    _arguments \
        {-o,--output-name}'[store the index to file X]' \
        {-k,--kmer-length}'[length of the kmers in the index (default 29, max 31)]' \
        {-w,--window-length}'[choose the minimizer from a window of N kmers (default 11)]' \
        {-c,--closed-syncmers}'[index closed syncmers instead of minimizers]' \
        {-s,--smer-length}'[use smers of length N in closed syncmers (default 18)]' \
        {-d,--distance-index}'[annotate the hits with positions in this distance index]' \
        {-l,--load-index}'[load the index from file X and insert the new kmers into it (overrides minimizer options)]' \
        {-g,--gbwt-name}'[use the GBWT index in file X (required with a non-GBZ graph)]' \
        {-p,--progress}'[show progress information]' \
        {-t,--threads}'[use N threads for index construction (default 12) (using more than 16 threads rarely helps)]' \
        "*: :_files"

}

function _vg_mod {
    _arguments \
        {-P,--label-paths}'[don'\''t edit with -i alignments, just use them for labeling the graph]' \
        {-c,--compact-ids}'[should we sort and compact the id space? (default false)]' \
        {-b,--break-cycles}'[use an approximate topological sort to break cycles in the graph]' \
        {-n,--normalize}'[normalize the graph so that edges are always non-redundant (nodes have unique starting and ending bases relative to neighbors, and edges that do not introduce new paths are removed and neighboring nodes are merged)]' \
        {-U,--until-normal}'[iterate normalization until convergence, or at most N times]' \
        {-z,--nomerge-pre}'[do not let normalize (-n, -U) zip up any pair of nodes that both belong to path with prefix STR]' \
        {-E,--unreverse-edges}'[flip doubly-reversing edges so that they are represented on the forward strand of the graph]' \
        {-s,--simplify}'[remove redundancy from the graph that will not change its path space]' \
        {-d,--dagify-step}'[copy strongly connected components of the graph N times, forwarding edges from old to new copies to convert the graph into a DAG]' \
        {-w,--dagify-to}'[copy strongly connected components of the graph forwarding edges from old to new copies to convert the graph into a DAG until the shortest path through each SCC is N bases long]' \
        {-L,--dagify-len-max}'[stop a dagification step if the unrolling component has this much sequence]' \
        {-f,--unfold}'[represent inversions accessible up to N from the forward component of the graph]' \
        {-O,--orient-forward}'[orient the nodes in the graph forward]' \
        {-N,--remove-non-path}'[keep only nodes and edges which are part of paths]' \
        {-A,--remove-path}'[keep only nodes and edges which are not part of any path]' \
        {-k,--keep-path}'[keep only nodes and edges in the path]' \
        {-R,--remove-null}'[removes nodes that have no sequence, forwarding their edges]' \
        {-g,--subgraph}'[gets the subgraph rooted at node ID, multiple allowed]' \
        {-x,--context}'[steps the subgraph out by N steps (default: 1)]' \
        {-p,--prune-complex}'[remove nodes that are reached by paths of --length which cross more than --edge-max edges]' \
        {-S,--prune-subgraphs}'[remove subgraphs which are shorter than --length]' \
        {-l,--length}'[for pruning complex regions and short subgraphs]' \
        {-X,--chop}'[chop nodes in the graph so they are not more than N bp long]' \
        {-u,--unchop}'[where two nodes are only connected to each other and by one edge replace the pair with a single node that is the concatenation of their labels]' \
        {-e,--edge-max}'[only consider paths which make edge choices at <= this many points]' \
        {-M,--max-degree}'[unlink nodes that have edge degree greater than N]' \
        {-m,--markers}'[join all head and tails nodes to marker nodes ('\''###'\'' starts and '\''$$$'\'' ends) of --length, for debugging]' \
        {-y,--destroy-node}'[remove node with given id]' \
        {-a,--cactus}'[convert to cactus graph representation]' \
        {-v,--sample-vcf}'[for a graph with allele paths, compute the sample graph from the given VCF]':file:_files \
        {-G,--sample-graph}'[subset an augmented graph to a sample graph using a Locus file]':file:_files \
        {-t,--threads}'[for tasks that can be done in parallel, use this many threads]' \
        "*: :_files"

}

function _vg_prune {
    _arguments \
        {-k,--kmer-length}'[kmer length used for pruning defaults: 24 with -P; 24 with -r; 24 with -u]' \
        {-e,--edge-max}'[remove the edges on kmers making > N edge choices defaults: 3 with -P; 3 with -r; 3 with -u]' \
        {-s,--subgraph-min}'[remove subgraphs of < N bases defaults: 33 with -P; 33 with -r; 33 with -u]' \
        {-M,--max-degree}'[if N > 0, remove nodes with degree > N before pruning defaults: 0 with -P; 0 with -r; 0 with -u]' \
        {-P,--prune}'[simply prune the graph (default)]' \
        {-r,--restore-paths}'[restore the edges on non-alt paths]' \
        {-u,--unfold-paths}'[unfold non-alt paths and GBWT threads]' \
        {-v,--verify-paths}'[verify that the paths exist after pruning (potentially very slow)]' \
        {-g,--gbwt-name}'[unfold the threads from this GBWT index]':file:_files \
        {-m,--mapping}'[store the node mapping for duplicates in this file (required with -u)]':file:_files \
        {-a,--append-mapping}'[append to the existing node mapping]' \
        {-p,--progress}'[show progress]' \
        {-t,--threads}'[use N threads (default: 12)]' \
        {-d,--dry-run}'[determine the validity of the combination of options]' \
        "*: :_files"

}

function _vg_sim {
    _arguments \
        {-x,--xg-name}'[use the graph in FILE (required)]':file:_files \
        {-n,--num-reads}'[simulate N reads or read pairs]' \
        {-l,--read-length}'[simulate reads of length N]' \
        {-r,--progress}'[show progress information]' \
        {-a,--align-out}'[write alignments in GAM-format]' \
        {-J,--json-out}'[write alignments in json]' \
        '--multi-position[annotate alignments with multiple reference positions]' \
        {-F,--fastq}'[match the error profile of NGS reads in FILE, repeat for paired reads (ignores -l,-f)]':file:_files \
        {-I,--interleaved}'[reads in FASTQ (-F) are interleaved read pairs]' \
        {-s,--random-seed}'[use this specific seed for the PRNG]' \
        {-e,--sub-rate}'[base substitution rate (default 0.0)]' \
        {-i,--indel-rate}'[indel rate (default 0.0)]' \
        {-d,--indel-err-prop}'[proportion of trained errors from -F that are indels (default 0.0)]' \
        {-S,--scale-err}'[scale trained error probabilities from -F by this much (default 1.0)]' \
        {-f,--forward-only}'[don'\''t simulate from the reverse strand]' \
        {-p,--frag-len}'[make paired end reads with given fragment length N]' \
        {-v,--frag-std-dev}'[use this standard deviation for fragment length estimation]' \
        {-N,--allow-Ns}'[allow reads to be sampled from the graph with Ns in them]' \
        '--max-tries[attempt sampling operations up to N times before giving up \[100\]]' \
        {-t,--threads}'[number of compute threads (only when using FASTQ with -F) \[1\]]' \
        {-P,--path}'[simulate from this path (may repeat; cannot also give -T)]':file:_files \
        {-A,--any-path}'[simulate from any path (overrides -P)]' \
        {-m,--sample-name}'[simulate from this sample (may repeat; requires -g)]' \
        {-R,--ploidy-regex}'[use the given comma-separated list of colon-delimited REGEX:PLOIDY rules to assign ploidies to contigs not visited by the selected samples, or to all contigs simulated from if no samples are used. Unmatched contigs get ploidy 2.]' \
        {-g,--gbwt-name}'[use samples from this GBWT index]':file:_files \
        {-T,--tx-expr-file}'[simulate from an expression profile formatted as RSEM output (cannot also give -P)]':file:_files \
        {-H,--haplo-tx-file}'[transcript origin info table from vg rna -i (required for -T on haplotype transcripts)]':file:_files \
        {-u,--unsheared}'[sample from unsheared fragments]' \
        {-E,--path-pos-file}'[output a TSV with sampled position on path of each read (requires -F)]':file:_files \
        "*: :_files"

}

function _vg_snarls {
    _arguments \
        {-A,--algorithm}'[compute snarls using '\''cactus'\'' or '\''integrated'\'' algorithms (default: integrated)]' \
        {-p,--pathnames}'[output variant paths as SnarlTraversals to STDOUT]' \
        {-r,--traversals}'[output SnarlTraversals for ultrabubbles.]':file:_files \
        {-e,--path-traversals}'[only consider traversals that correspond to paths in the graph. (-m ignored)]' \
        {-l,--leaf-only}'[restrict traversals to leaf ultrabubbles.]' \
        {-o,--top-level}'[restrict traversals to top level ultrabubbles]' \
        {-a,--any-snarl-type}'[compute traversals for any snarl type (not limiting to ultrabubbles)]' \
        {-m,--max-nodes}'[only compute traversals for snarls with <= N nodes (with degree > 1) \[10\]]' \
        {-n,--named-coordinates}'[produce snarl and traversal outputs in named-segment (GFA) space]' \
        {-T,--include-trivial}'[report snarls that consist of a single edge]' \
        {-s,--sort-snarls}'[return snarls in sorted order by node ID (for topologically ordered graphs)]' \
        {-v,--vcf}'[use vcf-based instead of exhaustive traversal finder with -r]':file:_files \
        {-f,--fasta}'[reference in FASTA format (required for SVs by -v)]':file:_files \
        {-i,--ins-fasta}'[insertion sequences in FASTA format (required for SVs by -v)]':file:_files \
        {-t,--threads}'[number of threads to use \[all available\]]' \
        "*: :_files"

}

function _vg_stats {
    _arguments \
        {-z,--size}'[size of graph]' \
        {-N,--node-count}'[number of nodes in graph]' \
        {-E,--edge-count}'[number of edges in graph]' \
        {-l,--length}'[length of sequences in graph]' \
        {-L,--self-loops}'[number of self-loops]' \
        {-s,--subgraphs}'[describe subgraphs of graph]' \
        {-H,--heads}'[list the head nodes of the graph]' \
        {-T,--tails}'[list the tail nodes of the graph]' \
        {-e,--nondeterm}'[list the nondeterministic edge sets]' \
        {-c,--components}'[print the strongly connected components of the graph]' \
        {-A,--is-acyclic}'[print if the graph is acyclic or not]' \
        {-n,--node}'[consider node with the given id]' \
        {-d,--to-head}'[show distance to head for each provided node]' \
        {-t,--to-tail}'[show distance to head for each provided node]' \
        {-a,--alignments}'[compute stats for reads aligned to the graph]':file:_files \
        {-r,--node-id-range}'[X:Y where X and Y are the smallest and largest node id in the graph, respectively]' \
        {-o,--overlap}'[for each overlapping path mapping in the graph write a table:]':file:_files \
        {-O,--overlap-all}'[print overlap table for the cartesian product of paths]' \
        {-R,--snarls}'[print statistics for each snarl]' \
        {-F,--format}'[graph format from {VG-Protobuf, PackedGraph, HashGraph, XG}. Can'\''t detect Protobuf if graph read from stdin]' \
        {-D,--degree-dist}'[print degree distribution of the graph.]' \
        {-v,--verbose}'[output longer reports]' \
        "*: :_files"

}

function _vg_view {
    _arguments \
        {-g,--gfa}'[output GFA format (default)]' \
        {-F,--gfa-in}'[input GFA format, reducing overlaps if they occur]' \
        {-v,--vg}'[output VG format]' \
        {-V,--vg-in}'[input VG format only]' \
        {-j,--json}'[output JSON format]' \
        {-J,--json-in}'[input JSON format]' \
        {-c,--json-stream}'[streaming conversion of a VG format graph in line delimited JSON format (this cannot be loaded directly via -J)]' \
        {-G,--gam}'[output GAM format (vg alignment format: Graph Alignment/Map)]' \
        {-Z,--translation-in}'[input is a graph translation description]' \
        {-t,--turtle}'[output RDF/turtle format (can not be loaded by VG)]' \
        {-T,--turtle-in}'[input turtle format.]' \
        {-r,--rdf_base_uri}'[set base uri for the RDF output]' \
        {-a,--align-in}'[input GAM format]' \
        {-A,--aln-graph}'[add alignments from GAM to the graph]' \
        {-q,--locus-in}'[input stream is Locus format]' \
        {-z,--locus-out}'[output stream Locus format]' \
        {-Q,--loci}'[input is Locus format for use by dot output]':file:_files \
        {-d,--dot}'[output dot format]' \
        {-S,--simple-dot}'[simplify the dot output; remove node labels, simplify alignments]' \
        {-u,--noseq-dot}'[shows size information instead of sequence in the dot output]' \
        {-e,--ascii-labels}'[use labels for paths or superbubbles with char/colors rather than emoji]' \
        {-Y,--ultra-label}'[label nodes with emoji/colors that correspond to ultrabubbles]' \
        {-m,--skip-missing}'[skip mappings to nodes not in the graph when drawing alignments]' \
        {-C,--color}'[color nodes that are not in the reference path (DOT OUTPUT ONLY)]' \
        {-p,--show-paths}'[show paths in dot output]' \
        {-w,--walk-paths}'[add labeled edges to represent paths in dot output]' \
        {-n,--annotate-paths}'[add labels to normal edges to represent paths in dot output]' \
        {-M,--show-mappings}'[with -p print the mappings in each path in JSON]' \
        {-I,--invert-ports}'[invert the edge ports in dot so that ne->nw is reversed]' \
        {-s,--random-seed}'[use this seed when assigning path symbols in dot output]' \
        {-b,--bam}'[input BAM or other htslib-parseable alignments]' \
        {-f,--fastq-in}'[input fastq (output defaults to GAM). Takes two positional file arguments if paired]' \
        {-X,--fastq-out}'[output fastq (input defaults to GAM)]' \
        {-i,--interleaved}'[fastq is interleaved paired-ended]' \
        {-L,--pileup}'[output VG Pileup format]' \
        {-l,--pileup-in}'[input VG Pileup format]' \
        {-B,--distance-in}'[input distance index]' \
        {-R,--snarl-in}'[input VG Snarl format]' \
        {-E,--snarl-traversal-in}'[input VG SnarlTraversal format]' \
        {-K,--multipath-in}'[input VG MultipathAlignment format (GAMP)]' \
        {-k,--multipath}'[output VG MultipathAlignment format (GAMP)]' \
        {-D,--expect-duplicates}'[don'\''t warn if encountering the same node or edge multiple times]' \
        {-x,--extract-tag}'[extract and concatenate messages with the given tag]' \
        '--verbose[explain the file being read with --extract-tag]' \
        '--threads[for parallel operations use this many threads \[1\]]' \
        "*: :_files"

}

function _vg_align {
    _arguments \
        {-s,--sequence}'[align a string to the graph in graph.vg using partial order alignment]' \
        {-Q,--seq-name}'[name the sequence using this value]' \
        {-j,--json}'[output alignments in JSON format (default GAM)]' \
        {-m,--match}'[use this match score (default: 1)]' \
        {-M,--mismatch}'[use this mismatch penalty (default: 4)]' \
        '--score-matrix[read a 5x5 integer substitution scoring matrix from a file]':file:_files \
        {-g,--gap-open}'[use this gap open penalty (default: 6)]' \
        {-e,--gap-extend}'[use this gap extension penalty (default: 1)]' \
        {-T,--full-l-bonus}'[provide this bonus for alignments that are full length (default: 5)]' \
        {-b,--banded-global}'[use the banded global alignment algorithm]' \
        {-p,--pinned}'[pin the (local) alignment traceback to the optimal edge of the graph]' \
        {-L,--pin-left}'[pin the first rather than last bases of the graph and sequence]' \
        {-r,--reference}'[don'\''t use an input graph--- run SSW alignment between -s and -r]' \
        {-D,--debug}'[print out score matrices and other debugging info]' \
        "*: :_files"

}

function _vg_annotate {
    _arguments \
        {-x,--xg-name}'[xg index or graph to annotate (required)]':file:_files \
        {-b,--bed-name}'[a BED file to convert to GAM. May repeat.]':file:_files \
        {-f,--gff-name}'[a GFF3 file to convert to GAM. May repeat.]':file:_files \
        {-g,--ggff}'[output at GGFF subgraph annotation file instead of GAM (requires -s)]' \
        {-s,--snarls}'[file containing snarls to expand GFF intervals into]':file:_files \
        {-a,--gam}'[file of Alignments to annotate (required)]':file:_files \
        {-x,--xg-name}'[xg index of the graph against which the Alignments are aligned (required)]':file:_files \
        {-p,--positions}'[annotate alignments with reference positions]' \
        {-m,--multi-position}'[annotate alignments with multiple reference positions]' \
        {-l,--search-limit}'[when annotating with positions, search this far for paths (default: read length)]' \
        {-b,--bed-name}'[annotate alignments with overlapping region names from this BED. May repeat.]':file:_files \
        {-n,--novelty}'[output TSV table with header describing how much of each Alignment is novel]' \
        {-t,--threads}'[use the specified number of threads]' \
        "*: :_files"

}

function _vg_chunk {
    _arguments \
        {-x,--xg-name}'[use this graph or xg index to chunk subgraphs]':file:_files \
        {-G,--gbwt-name}'[use this GBWT haplotype index for haplotype extraction (for -T)]':file:_files \
        {-a,--gam-name}'[chunk this gam file instead of the graph (multiple allowed)]':file:_files \
        {-g,--gam-and-graph}'[when used in combination with -a, both gam and graph will be chunked]' \
        {-p,--path}'[write the chunk in the specified (0-based inclusive, multiple allowed) path range TARGET=path\[:pos1\[-pos2\]\] to standard output]' \
        {-P,--path-list}'[write chunks for all path regions in (line - separated file). format for each as in -p (all paths chunked unless otherwise specified)]':file:_files \
        {-e,--input-bed}'[write chunks for all (0-based end-exclusive) bed regions]':file:_files \
        {-S,--snarls}'[write given path-range(s) and all snarls fully contained in them, as alternative to -c]':file:_files \
        {-r,--node-range}'[write the chunk for the specified node range to standard output]' \
        {-R,--node-ranges}'[write the chunk for each node range in (newline or whitespace separated) file]':file:_files \
        {-n,--n-chunks}'[generate this many id-range chunks, which are determined using the xg index]' \
        {-m,--gam-split-size}'[split gam (specified with -a, sort/index not required) up into chunks with at most N reads each]' \
        {-C,--components}'[create a chunk for each connected component. if a targets given with (-p, -P, -r, -R), limit to components containing them]' \
        {-M,--path-components}'[create a chunk for each path in the graph'\''s connected component]' \
        {-s,--chunk-size}'[create chunks spanning N bases (or nodes with -r/-R) for all input regions.]' \
        {-o,--overlap}'[overlap between chunks when using -s \[0\]]' \
        {-E,--output-bed}'[write all created chunks to a bed file]':file:_files \
        {-b,--prefix}'[write output chunk files with the given base name. Files for chunk i will be named: <BASENAME>-<i>-<name>-<start>-<length>.<ext> \[./chunk\]]' \
        {-c,--context-steps}'[expand the context of the chunk this many node steps \[1\]]' \
        {-l,--context-length}'[expand the context of the chunk by this many bp \[0\]]' \
        {-T,--trace}'[trace haplotype threads in chunks (and only expand forward from input coordinates). Produces a .annotate.txt file with haplotype frequencies for each chunk.]' \
        '--no-embedded-haplotypes[Don'\''t load haplotypes from the graph. It is possible to -T without any haplotypes available.]' \
        {-f,--fully-contained}'[only return GAM alignments that are fully contained within chunk]' \
        {-O,--output-fmt}'[Specify output format (vg, pg, hg, gfa). \[vg\]]' \
        {-t,--threads}'[for tasks that can be done in parallel, use this many threads \[1\]]' \
        {-h,--help}'[]' \
        "*: :_files"

}

function _vg_circularize {
    _arguments \
        '-p[--path <PATHNAME> circularize the path by connecting its head/tail node.]' \
        {-P,--pathfile}'[circularize all paths in the provided file.]':file:_files \
        {-P,--pathfile}'[circularize all paths in the provided file.   -a, --head <node_id> circularize a head and tail node (must provide a tail).]':file:_files \
        {-a,--head}'[<node_id> circularize a head and tail node (must provide a tail).]' \
        {-z,--tail}'[<tail_id> circularize a head and tail node (must provide a head).]' \
        '-d[--describe list all the paths in the graph.]' \
        "*: :_files"

}

function _vg_clip {
    _arguments \
        {-b,--bed}'[BED regions corresponding to path intervals of the graph to target]':file:_files \
        {-r,--snarls}'[Snarls from vg snarls (recomputed if not given unless -d and -P used).]':file:_files \
        {-d,--depth}'[Clip out nodes and edges with path depth below N]' \
        {-n,--max-nodes}'[Only clip out snarls with > N nodes]' \
        {-e,--max-edges}'[Only clip out snarls with > N edges]' \
        '-N[--max-nodes-shallow N Only clip out snarls with > N nodes not including nested snarls]' \
        '-E[--max-edges-shallow N Only clip out snarls with > N edges not including nested snarls]' \
        {-a,--max-avg-degree}'[Only clip out snarls with average degree > N]' \
        {-l,--max-reflen-prop}'[Ignore snarls whose reference traversal spans more than F (0<=F<=1) of the whole reference path]' \
        {-L,--max-reflen}'[Ignore snarls whose reference traversal spans more than N bp]' \
        {-c,--context}'[Search up to at most N steps from reference paths for candidate deletion edges \[1\]]' \
        {-P,--path-prefix}'[Do not clip out alleles on paths beginning with given prefix (such references must be specified either with -P or -b). Multiple allowed]' \
        {-m,--min-fragment-len}'[Don'\''t write novel path fragment if it is less than N bp long]' \
        {-B,--output-bed}'[Write BED-style file of affected intervals instead of clipped graph. Columns 4-9 are: snarl node-count edge-count shallow-node-count shallow-edge-count avg-degree]' \
        {-t,--threads}'[number of threads to use \[default: all available\]]' \
        {-v,--verbose}'[Print some logging messages]' \
        "*: :_files"

}

function _vg_combine {
    _arguments \
        {-c,--cat-proto}'[Merge graphs by converting each to Protobuf (if not already) and catting the results. Node IDs not modified \[DEPRECATED\]]' \
        {-p,--connect-paths}'[Add edges necessary to connect paths with the same name present in different graphs.]' \
        "*: :_files"

}

function _vg_convert {
    _arguments \
        {-g,--gfa-in}'[input in GFA format]' \
        {-r,--in-rgfa-rank}'[import rgfa tags with rank <= N as paths \[default=0\]]' \
        {-b,--gbwt-in}'[input graph is a GBWTGraph using the GBWT in FILE]':file:_files \
        '--ref-sample[change haplotypes for this sample to reference paths (may repeat)]' \
        {-T,--gfa-trans}'[write gfa id conversions to FILE]':file:_files \
        {-v,--vg-out}'[output in VG format]' \
        {-a,--hash-out}'[output in HashGraph format \[default\]]' \
        {-p,--packed-out}'[output in PackedGraph format]' \
        {-x,--xg-out}'[output in XG format]' \
        {-f,--gfa-out}'[output in GFA format]' \
        {-H,--drop-haplotypes}'[do not include haplotype paths in the output (useful with GBWTGraph / GBZ inputs)]' \
        {-P,--rgfa-path}'[write given path as rGFA tags instead of lines (multiple allowed, only rank-0 supported)]' \
        {-Q,--rgfa-prefix}'[write paths with given prefix as rGFA tags instead of lines (multiple allowed, only rank-0 supported)]' \
        {-B,--rgfa-pline}'[paths written as rGFA tags also written as lines]' \
        {-W,--no-wline}'[write all paths as GFA P-lines instead of W-lines. Allows handling multiple phase blocks and subranges used together.]' \
        '--gbwtgraph-algorithm[Always use the GBWTGraph library GFA algorithm. Not compatible with other GBWT output options or non-GBWT graphs.]' \
        '--vg-algorithm[Always use the VG GFA algorithm. Works with all options and graph types, but can'\''t preserve original GFA coordinates.]' \
        {-G,--gam-to-gaf}'[convert GAM FILE to GAF]':file:_files \
        {-F,--gaf-to-gam}'[convert GAF FILE to GAM]':file:_files \
        {-t,--threads}'[use N threads (defaults to numCPUs)]' \
        "*: :_files"

}

function _vg_depth {
    _arguments \
        {-k,--pack}'[supports created from vg pack for given input graph]':file:_files \
        {-d,--count-dels}'[count deletion edges within the bin as covering reference positions]' \
        {-g,--gam}'[read alignments from this GAM file (could be '\''-'\'' for stdin)]':file:_files \
        {-a,--gaf}'[read alignments from this GAF file (could be '\''-'\'' for stdin)]':file:_files \
        {-n,--max-nodes}'[maximum nodes to consider \[1000000\]]' \
        {-s,--random-seed}'[random seed for sampling nodes to consider]' \
        {-Q,--min-mapq}'[ignore alignments with mapping quality < N \[0\]]' \
        {-c,--count-cycles}'[count each time a path steps on a position (by default paths are only counted once)]' \
        {-p,--ref-path}'[reference path to call on (multipile allowed. defaults to all paths)]' \
        {-P,--paths-by}'[select the paths with the given name prefix]' \
        {-b,--bin-size}'[bin size (in bases) \[1\] (2 extra columns printed when N>1: bin-end-pos and stddev)]' \
        {-m,--min-coverage}'[ignore nodes with less than N coverage depth \[1\]]' \
        {-t,--threads}'[number of threads to use \[all available\]]' \
        "*: :_files"

}

function _vg_dotplot {
    _arguments \
        {-x,--xg}'[use the graph or the XG index FILE]':file:_files \
        "*: :_files"

}

function _vg_gamcompare {
    _arguments \
        {-d,--distance-index}'[use distances from this distance index instead of path position annotations]':file:_files \
        {-r,--range}'[distance within which to consider reads correct]' \
        {-T,--tsv}'[output TSV (correct, mq, aligner, read) compatible with plot-qq.R instead of GAM]' \
        {-a,--aligner}'[aligner name for TSV output \["vg"\]]' \
        {-s,--score-alignment}'[get a correctness score of the alignment (higher is better)]' \
        {-t,--threads}'[number of threads to use]' \
        "*: :_files"

}

function _vg_gampcompare {
    _arguments \
        {-G,--gam}'[alignments are in GAM format rather than GAMP]' \
        {-r,--range}'[distance within which to consider reads correct \[100\]]' \
        {-a,--aligner}'[aligner name for TSV output \["vg"\]]' \
        {-d,--distance}'[report minimum distance along a path rather than correctness]' \
        {-t,--threads}'[number of threads to use \[1\]]' \
        "*: :_files"

}

function _vg_gamsort {
    _arguments \
        {-i,--index}'[produce an index of the sorted GAM file]':file:_files \
        {-d,--dumb-sort}'[use naive sorting algorithm (no tmp files, faster for small GAMs)]' \
        {-p,--progress}'[Show progress.]' \
        {-t,--threads}'[Use the specified number of threads.]' \
        "*: :_files"

}

function _vg_genotype {
    _arguments \
        {-j,--json}'[output in JSON]' \
        {-v,--vcf}'[output in VCF]' \
        {-V,--recall-vcf}'[recall variants in a specific VCF file.]' \
        {-F,--fasta,-I,--insertions,-r,--ref}'[use the given path name as the reference path]' \
        {-c,--contig}'[use the given name as the VCF contig name]' \
        {-s,--sample}'[name the sample in the VCF with the given name]' \
        {-o,--offset}'[offset variant positions by this amount]' \
        {-l,--length}'[override total sequence length]' \
        {-a,--augmented}'[dump augmented graph to FILE]':file:_files \
        {-Q,--ignore_mapq}'[do not use mapping qualities]' \
        {-A,--no_indel_realign}'[disable indel realignment]' \
        {-d,--het_prior_denom}'[denominator for prior probability of heterozygousness]' \
        {-P,--min_per_strand}'[min unique reads per strand for a called allele to accept a call]' \
        {-E,--no_embed}'[don'\''t embed gam edits into graph]' \
        {-T,--traversal}'[traversal finder to use {reads, exhaustive, representative, adaptive} (adaptive)]' \
        {-p,--progress}'[show progress]' \
        {-t,--threads}'[number of threads to use]' \
        "*: :_files"

}

function _vg_inject {
    _arguments \
        {-x,--xg-name}'[use this graph or xg index (required)]':file:_files \
        {-t,--threads}'[number of threads to use]' \
        "*: :_files"

}

function _vg_paths {
    _arguments \
        {-x,--xg}'[use the paths and haplotypes in this graph FILE. Supports GBZ haplotypes. (Also accepts -v, --vg)]':file:_files \
        {-g,--gbwt}'[use the threads in the GBWT index in FILE (graph also required for most output options; -g takes priority over -x)]':file:_files \
        {-V,--extract-vg}'[output a path-only graph covering the selected paths]' \
        {-d,--drop-paths}'[output a graph with the selected paths removed]' \
        {-r,--retain-paths}'[output a graph with only the selected paths retained]' \
        {-X,--extract-gam}'[print (as GAM alignments) the stored paths in the graph]' \
        {-A,--extract-gaf}'[print (as GAF alignments) the stored paths in the graph]' \
        {-L,--list}'[print (as a list of names, one per line) the path (or thread) names]' \
        {-E,--lengths}'[print a list of path names (as with -L) but paired with their lengths]' \
        {-M,--metadata}'[print a table of path names and their metadata]' \
        {-C,--cyclicity}'[print a list of path names (as with -L) but paired with flag denoting the cyclicity]' \
        {-F,--extract-fasta}'[print the paths in FASTA format]' \
        {-c,--coverage}'[print the coverage stats for selected paths (not including cylces)]' \
        {-p,--paths-file}'[select the paths named in a file (one per line)]':file:_files \
        {-Q,--paths-by}'[select the paths with the given name prefix]' \
        {-S,--sample}'[select the haplotypes or reference paths for this sample]' \
        {-a,--variant-paths}'[select the variant paths added by '\''vg construct -a'\'']' \
        {-G,--generic-paths}'[select the generic, non-reference, non-haplotype paths]' \
        "*: :_files"

}

function _vg_simplify {
    _arguments \
        {-a,--algorithm}'[simplify using the given algorithm (small, rare; default: small)]' \
        {-t,--threads}'[use N threads to construct graph (defaults to numCPUs)]' \
        {-p,--progress}'[show progress]' \
        {-b,--bed-in}'[read in the given BED file in the cordinates of the original paths]' \
        {-B,--bed-out}'[output transformed features in the coordinates of the new paths]' \
        {-m,--min-size}'[remove leaf sites with fewer than N bases involved (default: 10)]' \
        {-v,--vcf}'[use the given VCF file to determine variant frequency (required)]':file:_files \
        {-f,--min-freq}'[remove variants with total alt frequency under FLOAT (default: 0)]' \
        {-c,--min-count}'[remove variants with total alt occurrence count under N (default: 0)]' \
        "*: :_files"

}

function _vg_surject {
    _arguments \
        {-x,--xg-name}'[use this graph or xg index (required)]':file:_files \
        {-t,--threads}'[number of threads to use]' \
        {-p,--into-path}'[surject into this path or its subpaths (many allowed, default: reference, then non-alt generic)]' \
        {-F,--into-paths}'[surject into path names listed in HTSlib sequence dictionary or path list FILE]':file:_files \
        {-i,--interleaved}'[GAM is interleaved paired-ended, so when outputting HTS formats, pair reads]' \
        {-M,--multimap}'[include secondary alignments to all overlapping paths instead of just primary]' \
        {-G,--gaf-input}'[input file is GAF instead of GAM]' \
        {-m,--gamp-input}'[input file is GAMP instead of GAM]' \
        {-c,--cram-output}'[write CRAM to stdout]' \
        {-b,--bam-output}'[write BAM to stdout]' \
        {-s,--sam-output}'[write SAM to stdout]' \
        {-l,--subpath-local}'[let the multipath mapping surjection produce local (rather than global) alignments]' \
        {-P,--prune-low-cplx}'[prune short and low complexity anchors during realignment]' \
        {-S,--spliced}'[interpret long deletions against paths as spliced alignments]' \
        {-A,--qual-adj}'[adjust scoring for base qualities, if they are available]' \
        {-N,--sample}'[set this sample name for all reads]' \
        {-R,--read-group}'[set this read group for all reads]' \
        {-f,--max-frag-len}'[reads with fragment lengths greater than N will not be marked properly paired in SAM/BAM/CRAM]' \
        {-L,--list-all-paths}'[annotate SAM records with a list of all attempted re-alignments to paths in SS tag]' \
        {-C,--compression}'[level for compression \[0-9\]]' \
        "*: :_files"

}

function _vg_trace {
    _arguments \
        {-x,--index}'[use this xg index or graph]':file:_files \
        {-G,--gbwt-name}'[use this GBWT haplotype index instead of any in the graph]':file:_files \
        {-n,--start-node}'[start at this node]' \
        {-d,--extend-distance}'[extend search this many nodes \[default=50\]]' \
        "*: :_files"

}

function _vg_vectorize {
    _arguments \
        {-x,--xg}'[An xg index or graph of interest]':file:_files \
        {-g,--gcsa}'[A gcsa2 index to use if generating MEM sketches]':file:_files \
        {-l,--aln-label}'[Rename every alignment to LABEL when outputting alignment name.]' \
        {-f,--format}'[Tab-delimit output so it can be used in R.]' \
        {-A,--annotate}'[Create a header with each node/edge'\''s name and a column with alignment names.]' \
        {-a,--a-hot}'[Instead of a 1-hot, output a vector of {0|1|2} for covered, reference, or alt.]' \
        {-w,--wabbit}'[Output a format that'\''s friendly to vowpal wabbit]' \
        {-M,--wabbit-mapping}'[output the mappings used for vowpal wabbit classes (default: print to stderr)]':file:_files \
        {-M,--wabbit-mapping}'[output the mappings used for vowpal wabbit classes (default   print to stderr)]':file:_files \
        {-m,--mem-sketch}'[Generate a MEM sketch of a given read based on the GCSA]' \
        {-i,--identity-hot}'[Output a score vector based on percent identity and coverage]' \
        "*: :_files"

}

function _vg_viz {
    _arguments \
        {-x,--xg}'[use this basis graph]':file:_files \
        {-i,--pack-in}'[use this compressed coverage format (multiple allowed)]':file:_files \
        {-n,--name}'[apply name to the previous .pack (multiple allowed)]' \
        {-o,--out}'[write to file (could be .png or .svg)]':file:_files \
        {-X,--width}'[write an image N pixels wide (default 1024)]' \
        {-Y,--height}'[write an image N pixels high (default 1024)]' \
        {-C,--show-cnv}'[visualize CNVs in paths on new rows (default uses text)]' \
        {-P,--hide-paths}'[hide reference paths in the graph]' \
        {-D,--hide-dna}'[suppress the visualization of DNA sequences]' \
        "*: :_files"

}

function _vg_benchmark {
    _arguments \
        {-p,--progress}'[show progress]' \
        "*: :_files"

}

function _vg_chain {
    _arguments \
        {-p,--progress}'[show progress]' \
        "*: :_files"

}

function _vg_cluster {
    _arguments \
        {-x,--xg-name}'[use this xg index or graph (required)]':file:_files \
        {-g,--gcsa-name}'[use this GCSA2/LCP index pair (both FILE and FILE.lcp)]':file:_files \
        {-m,--minimizer-name}'[use this minimizer index]':file:_files \
        {-d,--dist-name}'[cluster using this distance index (required)]':file:_files \
        {-c,--hit-cap}'[ignore minimizers with more than this many locations \[10\]]' \
        {-t,--threads}'[number of compute threads to use]' \
        "*: :_files"

}

function _vg_find {
    _arguments \
        {-x,--xg-name}'[use this xg index or graph (instead of rocksdb db)]':file:_files \
        {-n,--node}'[find node(s), return 1-hop context as graph]' \
        {-N,--node-list}'[a white space or line delimited list of nodes to collect]':file:_files \
        {-e,--edges-end}'[return edges on end of node with ID]' \
        {-s,--edges-start}'[return edges on start of node with ID]' \
        {-c,--context}'[expand the context of the subgraph this many steps]' \
        {-L,--use-length}'[treat STEPS in -c or M in -r as a length in bases]' \
        {-P,--position-in}'[find the position of the node (specified by -n) in the given path]':file:_files \
        {-I,--list-paths}'[write out the path names in the index]' \
        {-r,--node-range}'[get nodes from N to M]' \
        {-G,--gam}'[accumulate the graph touched by the alignments in the GAM]' \
        '--connecting-start[find the graph connecting from POS (node ID, + or -, node offset) to --connecting-end]' \
        '--connecting-end[find the graph connecting to POS (node ID, + or -, node offset) from --connecting-start]' \
        '--connecting-range[traverse up to INT bases when going from --connecting-start to --connecting-end (default: 100)]' \
        {-p,--path}'[find the node(s) in the specified path range(s) TARGET=path\[:pos1\[-pos2\]\]]' \
        {-R,--path-bed}'[read our targets from the given BED FILE]':file:_files \
        {-E,--path-dag}'[with -p or -R, gets any node in the partial order from pos1 to pos2, assumes id sorted DAG]' \
        {-W,--save-to}'[instead of writing target subgraphs to stdout, write one per given target to a separate file named PREFIX\[path\]:\[start\]-\[end\].vg]' \
        {-K,--subgraph-k}'[instead of graphs, write kmers from the subgraphs]' \
        {-H,--gbwt}'[when enumerating kmers from subgraphs, determine their frequencies in this GBWT haplotype index]':file:_files \
        {-l,--sorted-gam}'[use this sorted, indexed GAM file]':file:_files \
        {-o,--alns-on}'[write alignments which align to any of the nodes between N and M (inclusive)]' \
        {-A,--to-graph}'[get alignments to the provided subgraph]' \
        {-g,--gcsa}'[use this GCSA2 index of the sequence space of the graph (required for sequence queries)]':file:_files \
        {-S,--sequence}'[search for sequence STR using]' \
        {-M,--mems}'[describe the super-maximal exact matches of the STR (gcsa2) in JSON]' \
        {-B,--reseed-length}'[find non-super-maximal MEMs inside SMEMs of length at least N]' \
        {-f,--fast-reseed}'[use fast SMEM reseeding algorithm]' \
        {-Y,--max-mem}'[the maximum length of the MEM (default: GCSA2 order)]' \
        {-Z,--min-mem}'[the minimum length of the MEM (default: 1)]' \
        {-D,--distance}'[return distance on path between pair of nodes (-n). if -P not used, best path chosen heurstically]' \
        {-Q,--paths-named}'[return all paths whose names are prefixed with S (multiple allowed)]' \
        "*: :_files"

}

function _vg_mcmc {
    _arguments \
        {-i,--iteration-number}'[tells us the number of iterations to run mcmc_genotyper with]' \
        {-r,--seed}'[the seed we will use for the random number generator]' \
        {-s,--sample}'[sample name \[default=SAMPLE\]]' \
        {-p,--ref-path}'[reference path to call on (multipile allowed. defaults to all paths)]' \
        {-o,--ref-offset}'[offset in reference path (multiple allowed, 1 per path)]' \
        {-l,--ref-length}'[override length of reference in the contig field of output VCF]' \
        {-v,--vcf-out}'[write VCF output to this file]':file:_files \
        {-b,--burn-in}'[number of iterations to run original sample proposal only]' \
        {-g,--gamma-freq}'[the frequency (every n iterations) for which to re-make the gamma set (starts after burn-in)]' \
        "*: :_files"

}

function _vg_test {
    _arguments \
        {-\?,-h,--help}'[display usage information]' \
        {-l,--list-tests}'[list all/matching test cases]' \
        {-t,--list-tags}'[list all/matching tags]' \
        {-s,--success}'[include successful tests in output]' \
        {-b,--break}'[break into debugger on failure]' \
        {-e,--nothrow}'[skip exception tests]' \
        {-i,--invisibles}'[show invisibles (tabs, newlines)]' \
        {-o,--out}'[output filename]':file:_files \
        {-r,--reporter}'[reporter to use (defaults to console)]' \
        {-n,--name}'[suite name]' \
        {-a,--abort}'[abort at first failure]' \
        {-x,--abortx}'[abort after x failures]' \
        {-w,--warn}'[enable warnings]' \
        {-d,--durations}'[show test durations]' \
        {-D,--min-duration}'[show test durations for tests taking at least the given number of seconds]' \
        {-f,--input-file}'[load test names to run from a file]':file:_files \
        {-\#,--filenames-as-tags}'[adds a tag for the filename]' \
        {-c,--section}'[specify section to run]' \
        {-v,--verbosity}'[set output verbosity]' \
        '--list-test-names-only[list all/matching test cases names only]' \
        '--list-reporters[list all reporters]' \
        '--order[test case order (defaults to decl)]' \
        '--rng-seed[set a specific seed for random numbers]' \
        '--use-colour[should output be colourised]' \
        '--libidentify[report name and version according to libidentify standard]' \
        '--wait-for-keypress[waits for a keypress before]' \
        '--benchmark-samples[number of samples to collect (default: 100)]' \
        '--benchmark-resamples[number of resamples for the bootstrap (default: 100000)]' \
        '--benchmark-confidence-interval[confidence interval for the]' \
        '--benchmark-no-analysis[perform only measurements; do not perform any analysis]' \
        '--benchmark-warmup-time[amount of time in milliseconds]' \
        "*: :_files"

}

function _vg_validate {
    _arguments \
        {-o,--orphans}'[verify that all nodes have edges]' \
        {-a,--gam}'[verify that edits in the alignment fit on nodes in the graph]':file:_files \
        "*: :_files"

}

function _vg_version {
    _arguments \
        {-s,--slug}'[print only the one-line, whitespace-free version string]' \
        {-h,--help}'[print this help]' \
        "*: :_files"

}

_vg "$@"

